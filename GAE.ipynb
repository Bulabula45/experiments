{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c09af88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fea72263930>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "\n",
    "seed = 12345\n",
    "\n",
    "np.random.seed(seed)  # seed for numpy\n",
    "torch.manual_seed(seed)  # seed for PyTorch CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76b0d010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(adjacency):\n",
    "    \"\"\" \n",
    "    degree matrix\n",
    "    L=D^-0.5 * (A+I) * D^-0.5\n",
    "    \"\"\"\n",
    "    # adjacency += sp.eye(adjacency.shape[0])    # \n",
    "    adjacency =sp.coo_matrix(adjacency)\n",
    "    degree = np.array(adjacency.sum(1)) # \n",
    "    d_hat = sp.diags(np.power(degree, -0.5).flatten())\n",
    "    adj_normalized = d_hat.dot(adjacency).dot(d_hat).tocoo()\n",
    "    adj_normalized = sp.csc_matrix.todense(adj_normalized) #\n",
    "    return adj_normalized\n",
    "\n",
    "\n",
    "DEVICE='cpu'\n",
    "\n",
    "hidden_m =256   \n",
    "decod = 128\n",
    "LEARNING_RATE = 0.01\n",
    "WEIGHT_DACAY = 5e-4   \n",
    "\n",
    "BASE = '/Users/chensiang/Desktop/深度学习/GraLTR-LDA_main/independent_test'\n",
    "dataset_name = 'iLncDA-LTR'\n",
    "\n",
    "# training set\n",
    "adj = np.load(BASE+'/datasets/'+dataset_name+'/1044_LD.npy')\n",
    "\n",
    "# lncRNA-lncRNA adjacency matrix have been with self-loop\n",
    "lnc_x = np.load(BASE+'/datasets/'+dataset_name+'/'+dataset_name+'_lnc.npy')\n",
    "lnc_x = np.float32(lnc_x)\n",
    "\n",
    "# disease-disease adjacency matrix have been with self-loop \n",
    "dis_x = np.load(BASE+'/datasets/'+dataset_name+'/'+dataset_name+'_dis.npy')\n",
    "dis_x = np.float32(dis_x)\n",
    "\n",
    "# Construct the adjacency matrix A_LD\n",
    "A_LD = np.vstack((np.hstack((lnc_x,adj)),np.hstack((adj.T,dis_x))))\n",
    "A_LD = np.float32(A_LD) # \n",
    "# init the graph node feature\n",
    "X_LD = A_LD.copy() # \n",
    "\n",
    "LD_adj = normalization(A_LD.copy()) # \n",
    "\n",
    "\n",
    "A_L = lnc_x.copy() #\n",
    "A_L = normalization(A_L.copy())# \n",
    "X_L = X_LD[:lnc_x.shape[0]].copy() # \n",
    "\n",
    "A_D = dis_x.copy() #\n",
    "A_D = normalization(A_D.copy())# \n",
    "X_D = X_LD[lnc_x.shape[0]:].copy() # \n",
    "\n",
    "input_num = adj.shape[0] + adj.shape[1]\n",
    "\n",
    "\n",
    "A_L = torch.from_numpy(A_L)\n",
    "X_L = torch.from_numpy(X_L)\n",
    "A_D = torch.from_numpy(A_D)\n",
    "X_D = torch.from_numpy(X_D)\n",
    "LD_adj = torch.from_numpy(LD_adj)\n",
    "X_LD = torch.from_numpy(X_LD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bad6370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([594, 594]), torch.Size([594, 594]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_LD.shape, LD_adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e85564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import GAE\n",
    "\n",
    "class GCNEncoder(nn.Module):\n",
    "    def  __init__(self, in_channels, hidden_size, out_channels, dropout):\n",
    "        super(GCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_size, cached=True)\n",
    "        self.conv2 = GCNConv(hidden_size, out_channels, cached=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.dropout(x)\n",
    "        return self.conv2(x, edge_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ceccd31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/chensiang/Downloads/DG-AssocMiner_miner-disease-gene.tsv\",sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "656e478c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   0,    0,    0,  ...,  518,  518,  518],\n",
       "         [ 519,  520,  521,  ..., 7810, 7811, 7812]]),\n",
       " tensor([[ 519,  520,  521,  ..., 7810, 7811, 7812],\n",
       "         [   0,    0,    0,  ...,  518,  518,  518]]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis_idx = {}\n",
    "k = 0\n",
    "for dis in df.Disease_ID:\n",
    "    if dis not in dis_idx.keys():\n",
    "        dis_idx[dis] = k\n",
    "        k += 1\n",
    "\n",
    "gene_idx = {}\n",
    "for gene in df.Gene_ID:\n",
    "    if gene not in gene_idx.keys():\n",
    "        gene_idx[gene] = k\n",
    "        k += 1\n",
    "#0-518号疾病，519-7812号基因\n",
    "adj_size = len(dis_idx) + len(gene_idx)\n",
    "adj_matrix = torch.zeros((adj_size, adj_size))\n",
    "for dis, gene in zip(df.Disease_ID, df.Gene_ID):\n",
    "    adj_matrix[dis_idx[dis]][gene_idx[gene]] = 1\n",
    "    \n",
    "edge_idx = torch.cat([_.unsqueeze(0) for _ in torch.where(adj_matrix==1)])\n",
    "reverse_edge_idx = torch.cat([edge_idx[1].unsqueeze(0), edge_idx[0].unsqueeze(0)],dim=0)\n",
    "edge_idx, reverse_edge_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ab78b111",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 1\n",
    "hidden_dim = 128\n",
    "out_dim = 16\n",
    "num_epochs = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b0a8dd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data()\n",
    "data.num_nodes = adj_size\n",
    "data.edge_index = torch.cat((edge_idx, reverse_edge_idx), dim=1)\n",
    "data.x = torch.ones(data.num_nodes, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a572485b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = T.Compose([T.RandomLinkSplit(num_val=0.05, num_test=0.15, is_undirected=True,split_labels=True,add_negative_train_samples=True)])\n",
    "train_dataset, val_dataset, test_dataset = tfm(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "36ad6263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(num_nodes=7813, edge_index=[2, 34174], x=[7813, 1], pos_edge_label=[17087], pos_edge_label_index=[2, 17087], neg_edge_label=[17087], neg_edge_label_index=[2, 17087])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "178627d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, test AUC: 0.9575, test AP: 0.9471, train AUC: 0.9622, train AP: 0.9553, loss:1.0664\n",
      "Epoch: 200, test AUC: 0.9537, test AP: 0.9447, train AUC: 0.9574, train AP: 0.9536, loss:1.0597\n",
      "Epoch: 300, test AUC: 0.9568, test AP: 0.9457, train AUC: 0.9609, train AP: 0.9559, loss:1.0561\n",
      "Epoch: 400, test AUC: 0.9515, test AP: 0.9427, train AUC: 0.9572, train AP: 0.9540, loss:1.0433\n"
     ]
    }
   ],
   "source": [
    "def gae_train(train_data, gae_model, optimizer):\n",
    "    gae_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = gae_model.encode(train_data.x, train_data.edge_index)\n",
    "    loss = gae_model.recon_loss(z, train_data.pos_edge_label_index)\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "@torch.no_grad()\n",
    "def gae_test(test_data, gae_model):\n",
    "    gae_model.eval()\n",
    "    z = gae_model.encode(test_data.x, test_data.edge_index)\n",
    "    return gae_model.test(z, test_data.pos_edge_label_index, test_data.neg_edge_label_index)\n",
    "\n",
    "\n",
    "losses = []\n",
    "test_auc = []\n",
    "test_ap = []\n",
    "train_aucs = []\n",
    "train_aps = []\n",
    "\n",
    "gae_model = GAE(GCNEncoder(num_features, hidden_dim, out_dim, 0.5))\n",
    "optimizer = torch.optim.Adam(gae_model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    loss = gae_train(train_dataset, gae_model, optimizer)\n",
    "    losses.append(loss)\n",
    "    auc, ap = gae_test(test_dataset, gae_model)\n",
    "    test_auc.append(auc)\n",
    "    test_ap.append(ap)\n",
    "\n",
    "    train_auc, train_ap = gae_test(train_dataset, gae_model)\n",
    "\n",
    "    train_aucs.append(train_auc)\n",
    "    train_aps.append(train_ap)\n",
    "\n",
    "    if(epoch % 100 == 0):\n",
    "        print('Epoch: {:03d}, test AUC: {:.4f}, test AP: {:.4f}, train AUC: {:.4f}, train AP: {:.4f}, loss:{:.4f}'.format(epoch, auc, ap, train_auc, train_ap, loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a56b708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAE(\n",
      "  (encoder): GCNEncoder(\n",
      "    (conv1): GCNConv(594, 256)\n",
      "    (conv2): GCNConv(256, 128)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cj/wqz5lfws2tv2d_0dxv91bbmr0000gn/T/ipykernel_10367/1707029409.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgae_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_LD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_edge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgae_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/cj/wqz5lfws2tv2d_0dxv91bbmr0000gn/T/ipykernel_10367/1707029409.py\u001b[0m in \u001b[0;36mgae_train\u001b[0;34m(x, edge_index, gae_model, optimizer)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mgae_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgae_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgae_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecon_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch_geometric/nn/models/autoencoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;34mr\"\"\"Runs the encoder and computes node-wise latent variables.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/cj/wqz5lfws2tv2d_0dxv91bbmr0000gn/T/ipykernel_10367/903789800.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         out = self.propagate(edge_index, x=x, edge_weight=edge_weight,\n\u001b[0m\u001b[1;32m    199\u001b[0m                              size=None)\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m                         \u001b[0maggr_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0maggr_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, inputs, index, ptr, dim_size)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mas\u001b[0m \u001b[0mspecified\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maggr\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0margument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \"\"\"\n\u001b[0;32m--> 578\u001b[0;31m         return self.aggr_module(inputs, index, ptr=ptr, dim_size=dim_size,\n\u001b[0m\u001b[1;32m    579\u001b[0m                                 dim=self.node_dim)\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m                                      f\">= '{int(index.max()) + 1}')\")\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch_geometric/nn/aggr/basic.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, index, ptr, dim_size, dim)\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mptr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 dim: int = -2) -> Tensor:\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, x, index, ptr, dim_size, dim, reduce)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     def to_dense_batch(self, x: Tensor, index: Optional[Tensor] = None,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch_geometric/utils/scatter.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'sum'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'add'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_add_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "\n",
    "EPOCHS = 4000\n",
    "learning_rate = 0.01\n",
    "\n",
    "NUM_FEATURES = X_LD.shape[1]    \n",
    "HIDDEN_SIZE = 256\n",
    "OUT_CHANNELS = 128\n",
    "\n",
    "gae_model = GAE(GCNEncoder(NUM_FEATURES, HIDDEN_SIZE, OUT_CHANNELS, 0.5))\n",
    "print(gae_model)\n",
    "\n",
    "\n",
    "def gae_train(x, edge_index, gae_model, optimizer):\n",
    "    gae_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = gae_model.encode(x, edge_index)\n",
    "    loss = gae_model.recon_loss(z, edge_index)\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    return z, float(loss)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def gae_test(z, pos_edge_index, gae_model):\n",
    "    gae_model.eval()\n",
    "    neg_edge_index = negative_sampling(pos_edge_index, z.size(0))\n",
    "    return gae_model.test(z, pos_edge_index, val_edge_index)\n",
    "\n",
    "losses = []\n",
    "test_auc = []\n",
    "test_ap = []\n",
    "train_aucs = []\n",
    "train_aps = []\n",
    "\n",
    "optimizer = torch.optim.Adam(gae_model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    \n",
    "    \n",
    "    z, loss = gae_train(X_LD, train_edge_index, gae_model, optimizer)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    \n",
    "    auc, ap = gae_test(z, val_edge_index, gae_model)\n",
    "    test_auc.append(auc)\n",
    "    test_ap.append(ap)\n",
    "\n",
    "    train_auc, train_ap = gae_test(z, train_edge_index, gae_model)\n",
    "\n",
    "    train_aucs.append(train_auc)\n",
    "    train_aps.append(train_ap)\n",
    "    \n",
    "    if(epoch % 100 == 0):\n",
    "        print('Epoch: {:03d}, test AUC: {:.4f}, test AP: {:.4f}, train AUC: {:.4f}, train AP: {:.4f}, loss:{:.4f}'.format(epoch, auc, ap, train_auc, train_ap, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1645b3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "k_folds = 10\n",
    "index_matrix = np.mat(np.where(np.triu(A_LD) == 1))\n",
    "association_nam = index_matrix.shape[1]\n",
    "random_index = index_matrix.T.tolist()\n",
    "random.seed(seed)\n",
    "random.shuffle(random_index)\n",
    "CV_size = int(association_nam / k_folds)\n",
    "temp = np.array(random_index[:association_nam - association_nam %\n",
    "                                 k_folds]).reshape(k_folds, CV_size,  -1).tolist()\n",
    "temp[k_folds - 1] = temp[k_folds - 1] + \\\n",
    "        random_index[association_nam - association_nam % k_folds:]\n",
    "\n",
    "random_index = temp\n",
    "\n",
    "edge_index = torch.from_numpy(index_matrix)\n",
    "val_edge_index = torch.tensor(np.array(random_index[5])).transpose(0, 1)\n",
    "train_edge_index = torch.cat((torch.tensor(np.concatenate(random_index[:5])), torch.tensor(np.concatenate(random_index[6:])))).transpose(0, 1)\n",
    "\n",
    "edge_index.shape, val_edge_index.shape, train_edge_index.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.852px",
    "left": "823px",
    "right": "20px",
    "top": "119px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
