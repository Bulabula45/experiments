{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e75e1273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "352610cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "dataset = torchvision.datasets.MNIST(root='./data/', train=True, download=True,\n",
    "                                     transform=torchvision.transforms.Compose([\n",
    "                                         #torchvision.transforms.Resize(28),\n",
    "                                         torchvision.transforms.ToTensor(),\n",
    "                                         torchvision.transforms.Normalize(mean=[0.5],std=[0.5])\n",
    "                                     ]))\n",
    "for i in range(len(dataset)):\n",
    "    if i<=5:\n",
    "        print(dataset[i][0].shape)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb161125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 28, 28], dtype=torch.int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_size = torch.tensor([1, 28, 28],dtype=torch.int32)\n",
    "image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b6a3ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = torch.tensor([1, 28, 28])\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super(Generator, self).__init__()\n",
    "         \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(in_dim, 64),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 128),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 256),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 512),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 1024),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, torch.prod(image_size, dtype=torch.int32)),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, z):\n",
    "        # shape of z:[bsz, in_dim]\n",
    "        # shape of output:[bsz, 1, 28, 28]\n",
    "        out = self.model(z)\n",
    "        image = out.reshape(z.shape[0], *image_size)\n",
    "        return image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41f7fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "         \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(torch.prod(image_size, dtype=torch.int32), 1024),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 512),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 128),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, image):\n",
    "        # shape of image:[bsz, 1, 28, 28]\n",
    "        prob = self.model(image.reshape(image.shape[0], -1))\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dad55638",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 64\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True,drop_last=True)\n",
    "generator = Generator(latent_dim)\n",
    "g_optimizer = torch.optim.Adam(generator.parameters(), lr=0.0001)\n",
    "discriminator = Discriminator()\n",
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.0001)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae95e0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 2, 6, 0, 7, 8, 1, 1, 4, 7, 5, 3, 2, 5, 1, 3, 3, 1, 6, 2, 0, 0, 8, 8,\n",
      "        7, 1, 9, 6, 3, 9, 8, 4, 8, 7, 5, 1, 8, 1, 9, 1, 6, 8, 2, 6, 3, 3, 8, 7,\n",
      "        1, 9, 4, 2, 3, 0, 4, 0, 7, 7, 3, 1, 5, 1, 7, 2])\n",
      "tensor([9, 4, 4, 9, 4, 2, 5, 1, 5, 4, 8, 1, 6, 8, 4, 8, 9, 3, 2, 6, 7, 6, 4, 5,\n",
      "        1, 2, 7, 8, 6, 4, 5, 5, 2, 6, 4, 5, 7, 0, 8, 1, 3, 6, 1, 6, 2, 2, 4, 5,\n",
      "        2, 7, 1, 2, 8, 3, 5, 2, 0, 4, 9, 8, 7, 8, 9, 1])\n",
      "tensor([2, 1, 9, 1, 6, 0, 2, 8, 0, 5, 6, 4, 6, 2, 7, 8, 8, 8, 8, 3, 8, 7, 5, 5,\n",
      "        8, 5, 1, 1, 5, 1, 2, 0, 4, 7, 2, 7, 0, 3, 1, 8, 1, 1, 2, 7, 8, 2, 1, 3,\n",
      "        8, 3, 6, 4, 3, 3, 0, 6, 2, 9, 4, 1, 5, 3, 7, 6])\n"
     ]
    }
   ],
   "source": [
    "# dataloader在进入epoch循环之前shuffle=True，每个epoch加载的数据也会打乱\n",
    "for epoch in range(3):\n",
    "    k = 0\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        if k < 1:\n",
    "            print(batch[1])\n",
    "        else:\n",
    "            break\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26734e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(100):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        gt_images, _ = batch\n",
    "        z = torch.randn(64, latent_dim)\n",
    "        pred_images = generator(z)\n",
    "        \n",
    "        discriminator.eval()\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss = loss_fn(discriminator(pred_images), torch.ones(64, 1))\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        discriminator.train()\n",
    "        d_optimizer.zero_grad()\n",
    "        d_loss = 0.5*(loss_fn(discriminator(gt_images), torch.ones(64, 1)) + loss_fn(discriminator(pred_images.detach()), torch.zeros(64, 1)))\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        if(epoch%10==0 and i%500==0):\n",
    "            torchvision.utils.save_image(pred_images[0], f\"image_epoch{epoch}_step_{i}.png\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85871de1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
